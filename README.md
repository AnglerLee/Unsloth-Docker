# CUDA Unsloth Docker Environment

CUDA 12.1, cuDNN, Ubuntu 22.04 ê¸°ë°˜ì˜ Unsloth ê°œë°œ í™˜ê²½ì„ ìœ„í•œ Docker ì´ë¯¸ì§€ì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### ê¸°ë³¸ í™˜ê²½
- **OS**: Ubuntu 22.04 LTS
- **CUDA**: 12.1 with cuDNN 8
- **Python**: 3.11 (Miniconda)
- **ì‚¬ìš©ì**: angler (sudo ê¶Œí•œ í¬í•¨)

### ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€
- **AI/ML í”„ë ˆì„ì›Œí¬**: PyTorch, CUDA Toolkit, XFormers
- **Unsloth**: `unsloth[cu121-torch240]` (ìµœì‹  ë²„ì „)
- **ê°œë°œ ë„êµ¬**: git, vim, wget, curl, build-essential
- **ë„¤íŠ¸ì›Œí¬**: SSH ì„œë²„ (í¬íŠ¸ 22)

### ë„¤íŠ¸ì›Œí¬ ì„¤ì •
- **ì €ì¥ì†Œ**: ì¹´ì¹´ì˜¤ ë¯¸ëŸ¬ ì„œë²„ (mirror.kakao.com)
- **Proxy**: í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
- **Certificate**: ì‚¬ìš©ì ì •ì˜ ì¸ì¦ì„œ ì§€ì›

## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„

### 1. ì¸ì¦ì„œ íŒŒì¼ ì¤€ë¹„ (ì„ íƒì‚¬í•­)
```bash
mkdir certificates
# í•„ìš”í•œ .crt ë˜ëŠ” .pem íŒŒì¼ì„ certificates/ í´ë”ì— ë³µì‚¬
```

### 2. NVIDIA Docker ì„¤ì¹˜ í™•ì¸
```bash
# NVIDIA Docker runtime í™•ì¸
docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi
```

## ğŸ”§ ë¹Œë“œ ë° ì‹¤í–‰

### Docker ì´ë¯¸ì§€ ë¹Œë“œ
```bash
# ê¸°ë³¸ ë¹Œë“œ
docker build -t cuda-unsloth:latest .

# ë¹Œë“œ ë¡œê·¸ ìƒì„¸ ì¶œë ¥
docker build --progress=plain -t cuda-unsloth:latest .
```

### ì»¨í…Œì´ë„ˆ ì‹¤í–‰

#### ê¸°ë³¸ ì‹¤í–‰
```bash
docker run --gpus all -it cuda-unsloth:latest
```

#### í¬íŠ¸ í¬ì›Œë”© í¬í•¨ (SSH ì ‘ì†ìš©)
```bash
docker run --gpus all -it -p 2222:22 cuda-unsloth:latest
```

#### ë³¼ë¥¨ ë§ˆìš´íŠ¸ í¬í•¨
```bash
docker run --gpus all -it \
  -p 2222:22 \
  -v $(pwd)/workspace:/home/angler/workspace \
  cuda-unsloth:latest
```

#### ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
```bash
docker run --gpus all -d \
  --name unsloth-container \
  -p 2222:22 \
  -v $(pwd)/workspace:/home/angler/workspace \
  cuda-unsloth:latest
```

### SSH ì ‘ì†
```bash
# ì»¨í…Œì´ë„ˆ ì‹¤í–‰ í›„ SSHë¡œ ì ‘ì†
ssh -p 2222 angler@localhost

# ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸
# angler: anglerpassword
# root: rootpassword
```

## ğŸ’» VS Code ì‚¬ìš©ë²•

### 1. Docker Extension ì„¤ì¹˜
VS Codeì—ì„œ Docker Extensionì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.

### 2. ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì„¤ì •
VS Codeì˜ `settings.json`ì— ë‹¤ìŒ ì„¤ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```json
{
  "docker.containers.defaultRunOptions": [
    "--gpus", "all"
  ]
}
```

### 3. Dev Container ì„¤ì • (ì„ íƒì‚¬í•­)
í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.devcontainer/devcontainer.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "name": "CUDA Unsloth Environment",
  "image": "cuda-unsloth:latest",
  "runArgs": [
    "--gpus", "all"
  ],
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-python.jupyter",
        "ms-toolsai.jupyter"
      ]
    }
  },
  "forwardPorts": [22],
  "remoteUser": "angler",
  "workspaceFolder": "/home/angler/workspace"
}
```

### 4. VS Codeì—ì„œ ì»¨í…Œì´ë„ˆ ì‚¬ìš©

#### ë°©ë²• 1: Docker Extension ì‚¬ìš©
1. VS Codeì—ì„œ Docker Extension ì—´ê¸°
2. ì´ë¯¸ì§€ ëª©ë¡ì—ì„œ `cuda-unsloth:latest` ìš°í´ë¦­
3. "Run Interactive" ì„ íƒ
4. í„°ë¯¸ë„ì—ì„œ `--gpus all` ì˜µì…˜ í™•ì¸

#### ë°©ë²• 2: Dev Container ì‚¬ìš©
1. `Ctrl+Shift+P` â†’ "Dev Containers: Reopen in Container"
2. ìë™ìœ¼ë¡œ GPU ì˜µì…˜ì´ ì ìš©ëœ ì»¨í…Œì´ë„ˆì—ì„œ ì‘ì—…

#### ë°©ë²• 3: SSH ì—°ê²° ì‚¬ìš©
1. ì»¨í…Œì´ë„ˆë¥¼ SSH í¬íŠ¸ì™€ í•¨ê»˜ ì‹¤í–‰
2. VS Codeì—ì„œ Remote-SSH extension ì‚¬ìš©
3. `ssh angler@localhost -p 2222`ë¡œ ì—°ê²°

## ğŸ› ï¸ ì‚¬ìš© ì˜ˆì œ

### Python í™˜ê²½ í™•ì¸
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"Device count: {torch.cuda.device_count()}")
```

### Unsloth ì‚¬ìš© ì˜ˆì œ
```python
from unsloth import FastLanguageModel
import torch

# ëª¨ë¸ ë¡œë“œ ì˜ˆì œ
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-2-7b-bnb-4bit",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)
```

## ğŸ”§ í™˜ê²½ ë³€ìˆ˜

ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ ì„¤ì •ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë“¤:

```bash
# Proxy ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •)
export http_proxy=http://proxy.company.com:8080
export https_proxy=http://proxy.company.com:8080
export no_proxy=localhost,127.0.0.1,::1

# CUDA í™˜ê²½
export CUDA_HOME=/usr/local/cuda
export PATH=$PATH:/usr/local/cuda/bin
```

## ğŸ“ ì£¼ì˜ì‚¬í•­

1. **GPU ë©”ëª¨ë¦¬**: ëŒ€ìš©ëŸ‰ ëª¨ë¸ ì‚¬ìš© ì‹œ ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ í™•ì¸
2. **ë„¤íŠ¸ì›Œí¬**: í”„ë¡ì‹œ í™˜ê²½ì—ì„œëŠ” `.bashrc`ì˜ í”„ë¡ì‹œ ì„¤ì • ìˆ˜ì • í•„ìš”
3. **ì¸ì¦ì„œ**: íšŒì‚¬ ì¸ì¦ì„œê°€ í•„ìš”í•œ ê²½ìš° `certificates/` í´ë”ì— ì¶”ê°€
4. **í¬íŠ¸**: SSH ì ‘ì† ì‹œ í˜¸ìŠ¤íŠ¸ì˜ 2222 í¬íŠ¸ ì‚¬ìš© (ì¶©ëŒ ì‹œ ë³€ê²½)

## ğŸ› ë¬¸ì œ í•´ê²°

### ë¹Œë“œ ì‹¤íŒ¨ ì‹œ
```bash
# ìºì‹œ ì—†ì´ ë‹¤ì‹œ ë¹Œë“œ
docker build --no-cache -t cuda-unsloth:latest .
```

### GPU ì¸ì‹ ì•ˆë  ì‹œ
```bash
# NVIDIA Docker runtime ì¬ì„¤ì¹˜
# ë˜ëŠ” nvidia-container-toolkit ì—…ë°ì´íŠ¸
```

### SSH ì ‘ì† ì•ˆë  ì‹œ
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ SSH ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo service ssh status
sudo service ssh restart
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ Dockerfileì€ MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ê° í¬í•¨ëœ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” í•´ë‹¹ ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.